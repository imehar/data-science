{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "data_folder = os.path.join(\"data\", \"books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_books_data(folder=data_folder):\n",
    "    documents = []\n",
    "    authors = []\n",
    "    subfolders = [subfolder for subfolder in os.listdir(folder)\n",
    "                  if os.path.isdir(os.path.join(folder, subfolder))]\n",
    "    for author_number, subfolder in enumerate(subfolders):\n",
    "        full_subfolder_path = os.path.join(folder, subfolder)\n",
    "        for document_name in os.listdir(full_subfolder_path):\n",
    "            with open(os.path.join(full_subfolder_path, document_name)) as inf:\n",
    "                documents.append(inf.read())\n",
    "                authors.append(author_number)\n",
    "    return documents, np.array(authors, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = os.path.join(data_folder,'train')\n",
    "documents, classes = load_books_data(train_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents), len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_words = [\"a\", \"able\", \"aboard\", \"about\", \"above\", \"absent\",\n",
    "                  \"according\" , \"accordingly\", \"across\", \"after\", \"against\",\n",
    "                  \"ahead\", \"albeit\", \"all\", \"along\", \"alongside\", \"although\",\n",
    "                  \"am\", \"amid\", \"amidst\", \"among\", \"amongst\", \"amount\", \"an\",\n",
    "                    \"and\", \"another\", \"anti\", \"any\", \"anybody\", \"anyone\",\n",
    "                    \"anything\", \"are\", \"around\", \"as\", \"aside\", \"astraddle\",\n",
    "                    \"astride\", \"at\", \"away\", \"bar\", \"barring\", \"be\", \"because\",\n",
    "                    \"been\", \"before\", \"behind\", \"being\", \"below\", \"beneath\",\n",
    "                    \"beside\", \"besides\", \"better\", \"between\", \"beyond\", \"bit\",\n",
    "                    \"both\", \"but\", \"by\", \"can\", \"certain\", \"circa\", \"close\",\n",
    "                    \"concerning\", \"consequently\", \"considering\", \"could\",\n",
    "                    \"couple\", \"dare\", \"deal\", \"despite\", \"down\", \"due\", \"during\",\n",
    "                    \"each\", \"eight\", \"eighth\", \"either\", \"enough\", \"every\",\n",
    "                    \"everybody\", \"everyone\", \"everything\", \"except\", \"excepting\",\n",
    "                    \"excluding\", \"failing\", \"few\", \"fewer\", \"fifth\", \"first\",\n",
    "                    \"five\", \"following\", \"for\", \"four\", \"fourth\", \"from\", \"front\",\n",
    "                    \"given\", \"good\", \"great\", \"had\", \"half\", \"have\", \"he\",\n",
    "                    \"heaps\", \"hence\", \"her\", \"hers\", \"herself\", \"him\", \"himself\",\n",
    "                    \"his\", \"however\", \"i\", \"if\", \"in\", \"including\", \"inside\",\n",
    "                    \"instead\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keeping\",\n",
    "                    \"lack\", \"less\", \"like\", \"little\", \"loads\", \"lots\", \"majority\",\n",
    "                    \"many\", \"masses\", \"may\", \"me\", \"might\", \"mine\", \"minority\",\n",
    "                    \"minus\", \"more\", \"most\", \"much\", \"must\", \"my\", \"myself\",\n",
    "                    \"near\", \"need\", \"neither\", \"nevertheless\", \"next\", \"nine\",\n",
    "                    \"ninth\", \"no\", \"nobody\", \"none\", \"nor\", \"nothing\",\n",
    "                    \"notwithstanding\", \"number\", \"numbers\", \"of\", \"off\", \"on\",\n",
    "                    \"once\", \"one\", \"onto\", \"opposite\", \"or\", \"other\", \"ought\",\n",
    "                    \"our\", \"ours\", \"ourselves\", \"out\", \"outside\", \"over\", \"part\",\n",
    "                    \"past\", \"pending\", \"per\", \"pertaining\", \"place\", \"plenty\",\n",
    "                    \"plethora\", \"plus\", \"quantities\", \"quantity\", \"quarter\",\n",
    "                    \"regarding\", \"remainder\", \"respecting\", \"rest\", \"round\",\n",
    "                    \"save\", \"saving\", \"second\", \"seven\", \"seventh\", \"several\",\n",
    "                    \"shall\", \"she\", \"should\", \"similar\", \"since\", \"six\", \"sixth\",\n",
    "                    \"so\", \"some\", \"somebody\", \"someone\", \"something\", \"spite\",\n",
    "                    \"such\", \"ten\", \"tenth\", \"than\", \"thanks\", \"that\", \"the\",\n",
    "                    \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"thence\",\n",
    "                  \"therefore\", \"these\", \"they\", \"third\", \"this\", \"those\",\n",
    "\"though\", \"three\", \"through\", \"throughout\", \"thru\", \"thus\",\n",
    "\"till\", \"time\", \"to\", \"tons\", \"top\", \"toward\", \"towards\",\n",
    "\"two\", \"under\", \"underneath\", \"unless\", \"unlike\", \"until\",\n",
    "\"unto\", \"up\", \"upon\", \"us\", \"used\", \"various\", \"versus\",\n",
    "\"via\", \"view\", \"wanting\", \"was\", \"we\", \"were\", \"what\",\n",
    "\"whatever\", \"when\", \"whenever\", \"where\", \"whereas\",\n",
    "\"wherever\", \"whether\", \"which\", \"whichever\", \"while\",\n",
    "                  \"whilst\", \"who\", \"whoever\", \"whole\", \"whom\", \"whomever\",\n",
    "\"whose\", \"will\", \"with\", \"within\", \"without\", \"would\", \"yet\",\n",
    "\"you\", \"your\", \"yours\", \"yourself\", \"yourselves\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "extractor = CountVectorizer(vocabulary=function_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1,10]}\n",
    "svr = SVC(gamma='scale')\n",
    "grid = GridSearchCV(svr, parameters,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline1 = Pipeline([('feature_extraction', extractor),\n",
    "                      ('clf', grid)\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 s, sys: 8.59 ms, total: 14 s\n",
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scores = cross_val_score(pipeline1, documents, classes,cv=5,scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6163598387842297\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 20s, sys: 3.84 s, total: 5min 24s\n",
      "Wall time: 5min 49s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = Pipeline([('feature_extraction',CountVectorizer(analyzer='char', ngram_range=(3, 3))),\n",
    "                    ('classifier', grid)\n",
    "                    ])\n",
    "scores = cross_val_score(pipeline, documents, classes,cv=5,scoring='f1_weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.838\n"
     ]
    }
   ],
   "source": [
    "print(\"Score: {:.3f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
